{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.svm import SVR\n",
    "import time\n",
    "import chainer.functions as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to append all the data and shuffle it. so it would scatter properly.\n",
    "\n",
    "Using the cleaned data which store in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Data1.txt', 'r')\n",
    "x1 = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Data2.txt', 'r')\n",
    "x2 = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Data3.txt', 'r')\n",
    "x3 = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x1+x2+x3\n",
    "random.shuffle(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X now become a list of string as we read from txt file.\n",
    "we need to convert the string into list.\n",
    "\n",
    "[1:29999] is all the input x\n",
    "\n",
    "[30001:30003] is the score. or or [30001:30004] if it is 100(as all scores is between 80-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.762722730636597\n"
     ]
    }
   ],
   "source": [
    "data1_fin = []\n",
    "start = time.time()\n",
    "for index in range(10000):\n",
    "    temp_data = x[index][1:29999]\n",
    "    if x[index][30003] == '0': #the score is 100\n",
    "        score = float(x[index][30001:30004])\n",
    "    else: #the score is between 80-99\n",
    "        score = float(x[index][30001:30003])\n",
    "    indx = int(x[index][30005:-2])\n",
    "    temp_data1 = temp_data.split(', ')\n",
    "    data = [float(i) for i in temp_data1]\n",
    "    data.append(score)\n",
    "    data.append(indx)\n",
    "    data1_fin.append(data)\n",
    "\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "y = list()\n",
    "\n",
    "for i in range(len(data1_fin)):\n",
    "    x.append(data1_fin[i][0:-2])\n",
    "    y.append(data1_fin[i][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_data = len(x)\n",
    "train_ratio = 0.8 #how much data will be used in training\n",
    "slice_position = int(number_of_data * train_ratio)\n",
    "x_train = np.array(x[:slice_position])\n",
    "y_train = np.array(y[:slice_position])\n",
    "x_test = np.array(x[slice_position:])\n",
    "y_test = np.array(y[slice_position:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning the model. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time:  544.7037029266357\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(x_train, y_train) \n",
    "end= time.time()\n",
    "print(\"Used time: \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict  and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of test data: 9.30154004145025\n"
     ]
    }
   ],
   "source": [
    "t_test = clf.predict(x_test)\n",
    "loss = F.mean_squared_error(t_test, y_test)\n",
    "print(\"loss of test data:\", loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss of SVR is much higher than nerual network.\n",
    "\n",
    "One of the reasons might be that nerual network is more flexible. The elements existed in the hidden layer will require the same amount of weights. Which means there are more possible way to calculate the result thus the model is more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
